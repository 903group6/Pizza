import json
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag				

#load json				
test = json.loads(open("test.json").read())
text = test[0].get("request_text_edit_aware")
tokens = word_tokenize(text)
pos_tag(tokens)

#pretty print json
with open('data.txt', 'w') as outfile:
    json.dump(test, outfile,sort_keys=True, indent=4, separators=(',', ': '))